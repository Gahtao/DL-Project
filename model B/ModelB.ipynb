{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bacd85b8",
   "metadata": {},
   "source": [
    "## Simple CNN Model Definition\n",
    "\n",
    "### Model Architecture\n",
    "1. **Convolutional Layers:**\n",
    "   - `self.conv1`: The first convolutional layer takes the input (RGB images) and produces feature maps with 16 output channels. The kernel size is set to 3 and padding needs to be 1 to keep the input dimension.\n",
    "   - `self.conv2`: The second convolutional layer takes the output of the first after the activation funtion and pooling are applied and produces a feature map with 32 channels, and has the the same kernel size and padding (3 and 1).\n",
    "   - `self.conv3`: The third convolutional layer further increases the number of output channels to 64.\n",
    "\n",
    "2. **Activation and Pooling:**\n",
    "   - `self.relu`: Rectified Linear Unit (ReLU) activation function is applied after each convolutional layer to introduce non-linearity.\n",
    "   - `self.pool`: Max-pooling layer with a kernel size of 2 and a stride of 2 is used to downsample the spatial dimensions.\n",
    "\n",
    "3. **Fully Connected Layers:**\n",
    "   - `self.fc1`: The first fully connected layer takes the flattened output from the last convolutional layer and maps it to 64 units.\n",
    "   - `self.fc2`: The final fully connected layer maps the 64 units to the output space with 10 units, corresponding to the number of classes in CIFAR-10.\n",
    "\n",
    "### Forward Pass\n",
    "The `forward` method defines the forward pass of the model. It specifies how input data flows through the layers to produce the final output. Convolutional and pooling layers are followed by activation functions, and the fully connected layers provide the classification logits. Note that the same relu and pooling layers are used in several parts. That is ok as these layers do not have parameters and are only applying the same function to any input, so no separate layers are needed.\n",
    "\n",
    "This simple CNN serves as a starting point for image classification tasks and can be further customized or extended for more complex problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2af05",
   "metadata": {},
   "source": [
    "Channel = 1 \n",
    "\n",
    "Padding = 2 (because dimension is 2) #only use if moving your filter would move you outside the convolution, so it's not mandatory\n",
    "\n",
    "filter size = width, height and channels (depends on the input size)\n",
    "\n",
    "Stride = how much youÂ´d have overlap in your steps\n",
    "\n",
    "Input first layer = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737c9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc92db29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.49767117e-03, 2.65710079e-03, 8.56382831e-04, ...,\n",
       "        2.75684800e-02, 2.11968720e-02, 1.92393452e-01],\n",
       "       [3.28047574e-03, 3.68075375e-03, 1.22681842e-03, ...,\n",
       "        3.15997489e-02, 2.90498883e-02, 1.78899750e-01],\n",
       "       [9.93582653e-04, 1.80864183e-03, 2.25268095e-03, ...,\n",
       "        4.00969684e-02, 1.05315924e-01, 3.62034291e-01],\n",
       "       ...,\n",
       "       [3.32125808e-07, 5.40772930e-07, 4.51911092e-07, ...,\n",
       "        4.52556871e-02, 4.99580149e-03, 1.27987994e-04],\n",
       "       [2.44497983e-07, 3.73876105e-07, 3.30896739e-07, ...,\n",
       "        2.76186783e-02, 3.27911088e-03, 1.63190067e-04],\n",
       "       [2.36694547e-07, 3.31006930e-07, 3.02130530e-07, ...,\n",
       "        1.24492105e-02, 1.89289649e-03, 1.77580456e-04]],\n",
       "      shape=(128, 407), dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"c:/Users/gaian/Documents/1f_1018.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168bce81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
