{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d62dcf",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f6b36188",
   "metadata": {},
   "source": [
    "#load data\n",
    "import convenience\n",
    "\n",
    "df_train_val, sample_rates = convenience.load_train()\n",
    "df_train_val['augmented_data'] = df_train_val.audio\n",
    "df_train_val.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e8db9f",
   "metadata": {},
   "source": [
    "sr = list(sample_rates)[0]\n",
    "sr\n",
    "\n",
    "#initialize sr variable (sampling rate) "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1374752",
   "metadata": {},
   "source": [
    "import torch"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f07b9",
   "metadata": {},
   "source": [
    "waveform = df_train_val.audio[0]\n",
    "print(waveform)\n",
    "waveform.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0752154c",
   "metadata": {},
   "source": [
    "#### Librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c3057c",
   "metadata": {},
   "source": [
    "In this part I apply different types of augmentation techniques. They're programmed in a pipeline, where the output of the previous is the input to the next one. \n",
    "If you want to apply the augmentation technique to a 'clean slate', apply it to df_train_val['augmented'].\n",
    "\n",
    "Code is adapted from: https://www.kaggle.com/code/huseinzol05/sound-augmentation-librosa#apply-hpss \n",
    "\n",
    "(Please note it would be a good idea to see for which augmentations the model has the best performance, yet also a good generalizability!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe98db",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import librosa \n",
    "\n",
    "import seaborn as sns \n",
    "sns.set() #iirc mostly for visuals \n",
    "import tensorflow as tf\n",
    "from IPython.display import Audio"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f5bd9",
   "metadata": {},
   "source": [
    "#pitch shifted audio\n",
    "#This is the begining of the pipeline, so df_train_val is used. \n",
    "pitch_shift_audio = [] #I always create a seperate list to avoid overwriting the original variable\n",
    "for file in df_train_val['augmented_data']:\n",
    "    audio_pitch = file.numpy() #data has to be a numpy array for Librosa to work\n",
    "    bins_per_octave = 12 \n",
    "    pitch_pm = 2 \n",
    "    pitch_change =  pitch_pm * 2*(np.random.uniform())  #every audiofile has a random pitch change (can be tweaked)\n",
    "    \n",
    "    pitch_shift_audio.append(librosa.effects.pitch_shift(audio_pitch, sr = 16000, n_steps=pitch_change, bins_per_octave=bins_per_octave)) \n",
    "\n",
    "print(pitch_shift_audio)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4831c",
   "metadata": {},
   "source": [
    "#change speed\n",
    "#notice how pitch_shift_audio is the input for this part (so no .numpy needed anymore)\n",
    "speed_shift_audio = []\n",
    "for file in pitch_shift_audio:\n",
    "    audio_speed = file \n",
    "    speed_change = np.random.uniform(low=0.9,high=1.1) #strength of the effect (can be tweaked)\n",
    "    tmp = librosa.effects.time_stretch(audio_speed, rate = speed_change) \n",
    "    minlen = min(audio_speed.shape[0], tmp.shape[0])\n",
    "    audio_speed *= 0 \n",
    "    audio_speed [0:minlen] = tmp[0:minlen] \n",
    "    \n",
    "    speed_shift_audio.append(audio_speed)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464779a7",
   "metadata": {},
   "source": [
    "#distribution noise\n",
    "noise_dist_audio = []\n",
    "\n",
    "for file in speed_shift_audio:\n",
    "    audio_noise = file\n",
    "    noise_amp = 0.005*np.random.uniform()*np.amax(audio_noise) #random audio noise, can be changed to any distribution from https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html\n",
    "    audio_noise = audio_noise + noise_amp * np.random.normal(size= audio_noise.shape[0]) #mathy math for noise\n",
    "    \n",
    "    noise_dist_audio.append(audio_noise) "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffac4d8",
   "metadata": {},
   "source": [
    "#random shift\n",
    "rand_shift_audio = []\n",
    "\n",
    "for file in noise_dist_audio:\n",
    "    audio_shift = file\n",
    "    timeshift_fac = 0.2 *2*(np.random.uniform()-0.5)  # up to 20% of length shift (can be tweaked)\n",
    "    start = int(audio_shift.shape[0] * timeshift_fac)\n",
    "    if (start > 0): \n",
    "        audio_shift = np.pad(audio_shift,(start,0),mode='constant')[0:audio_shift.shape[0]]\n",
    "    else:\n",
    "        audio_shift = np.pad(audio_shift,(0,-start),mode='constant')[0:audio_shift.shape[0]]\n",
    "    Audio(audio_shift, rate= sr)\n",
    "    \n",
    "    rand_shift_audio.append(audio_shift)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d2977",
   "metadata": {},
   "source": [
    "#stretching\n",
    "stretch_shift_audio = []\n",
    "\n",
    "for file in rand_shift_audio:\n",
    "    input_length = len(file)\n",
    "    streching = file\n",
    "    streching = librosa.effects.time_stretch(streching , rate = 1.1) #similar code to speed up due to file needing to fit audio\n",
    "    if len(streching) > input_length:\n",
    "        streching = streching[:input_length]\n",
    "    else:\n",
    "        streching = np.pad(streching, (0, max(0, input_length - len(streching))), \"constant\")\n",
    "\n",
    "    stretch_shift_audio.append(streching)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d2373",
   "metadata": {},
   "source": [
    "#supposed to convert the augmented data back into the df, in tensor form, but I was unable to make it work, kept giving dimension errors\n",
    "#there could be a hidden issue in the functions used where it changes the dimensions, I suspect speed or stretch \n",
    "#I would try to run all parts of the pipeline seperately and see from where the issue arrises \n",
    "\n",
    "#augmented_data = torch.tensor(stretch_shift_audio)\n",
    "\n",
    "#df_train_val['augmented_data'] = augmented_data\n",
    "#df_train_val.head()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
