{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67c0ca6",
   "metadata": {},
   "source": [
    "## Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3512c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import convenience\n",
    "df_train_val, sample_rates = convenience.load_train()\n",
    "df_train_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2adaf40",
   "metadata": {},
   "source": [
    "## Loop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 16000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m sr = \u001b[38;5;28mlist\u001b[39m(sample_rates)[\u001b[32m0\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(target_duration, sr)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df_train_val, _ = \u001b[43mconvenience\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloop_audio_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_duration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m df_train_val.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DL-Project/model B/convenience.py:67\u001b[39m, in \u001b[36mloop_audio_df\u001b[39m\u001b[34m(df, target_duration, sr)\u001b[39m\n\u001b[32m     64\u001b[39m         looped_audio = np.concatenate((looped_audio, silence))\n\u001b[32m     65\u001b[39m     looped_audios.append(torch.tensor(looped_audio))\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlooped_audio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m = looped_audios\n\u001b[32m     69\u001b[39m looped_lengths = [\u001b[38;5;28mlen\u001b[39m(x)/sr \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df.looped_audio]\n\u001b[32m     70\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mlooped_length\u001b[39m\u001b[33m\"\u001b[39m] = looped_lengths\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/DL_accent/lib/python3.13/site-packages/pandas/core/frame.py:4311\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4308\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4310\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4311\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/DL_accent/lib/python3.13/site-packages/pandas/core/frame.py:4524\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4514\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4515\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4516\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4517\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4522\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4523\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4524\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4527\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4528\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4529\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4530\u001b[39m     ):\n\u001b[32m   4531\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4532\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/DL_accent/lib/python3.13/site-packages/pandas/core/frame.py:5267\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m   5266\u001b[39m     com.require_length_match(value, \u001b[38;5;28mself\u001b[39m.index)\n\u001b[32m-> \u001b[39m\u001b[32m5267\u001b[39m arr = \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   5268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5269\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[32m   5270\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m value.dtype == \u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5273\u001b[39m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[32m   5274\u001b[39m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n\u001b[32m   5275\u001b[39m     warnings.warn(\n\u001b[32m   5276\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSetting an Index with object dtype into a DataFrame will stop \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5277\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minferring another dtype in a future version. Cast the Index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5280\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   5281\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/DL_accent/lib/python3.13/site-packages/pandas/core/construction.py:654\u001b[39m, in \u001b[36msanitize_array\u001b[39m\u001b[34m(data, index, dtype, copy, allow_2d)\u001b[39m\n\u001b[32m    651\u001b[39m     subarr = _try_cast(data, dtype, copy)\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     subarr = \u001b[43mmaybe_convert_platform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m subarr.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    656\u001b[39m         subarr = cast(np.ndarray, subarr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/DL_accent/lib/python3.13/site-packages/pandas/core/dtypes/cast.py:130\u001b[39m, in \u001b[36mmaybe_convert_platform\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m    127\u001b[39m arr: ArrayLike\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mrange\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     arr = \u001b[43mconstruct_1d_object_array_from_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# The caller is responsible for ensuring that we have np.ndarray\u001b[39;00m\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m#  or ExtensionArray here.\u001b[39;00m\n\u001b[32m    134\u001b[39m     arr = values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/DL_accent/lib/python3.13/site-packages/pandas/core/dtypes/cast.py:1600\u001b[39m, in \u001b[36mconstruct_1d_object_array_from_listlike\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1597\u001b[39m \u001b[38;5;66;03m# numpy will try to interpret nested lists as further dimensions, hence\u001b[39;00m\n\u001b[32m   1598\u001b[39m \u001b[38;5;66;03m# making a 1D array that contains list-likes is a bit tricky:\u001b[39;00m\n\u001b[32m   1599\u001b[39m result = np.empty(\u001b[38;5;28mlen\u001b[39m(values), dtype=\u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1600\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m = values\n\u001b[32m   1601\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/DL_accent/lib/python3.13/site-packages/torch/_tensor.py:1227\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy()\n\u001b[32m   1226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "target_duration = math.ceil(df_train_val.length.max())\n",
    "sr = list(sample_rates)[0]\n",
    "\n",
    "df_train_val, _ = convenience.loop_audio_df(df_train_val, target_duration, sr)\n",
    "df_train_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9beda8",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c703d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "df_train_val['audio_norm'] = df_train_val.looped_audio/[torch.max(torch.abs(df_train_val.looped_audio[i])) for i in range(len(df_train_val.looped_audio))]\n",
    "df_train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cf969",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = [torch.max(torch.abs(df_train_val.audio_norm[i])) for i in range(len(df_train_val.audio_norm))]\n",
    "mins = [torch.min(torch.abs(df_train_val.audio_norm[i])) for i in range(len(df_train_val.audio_norm))]\n",
    "means = [torch.sum(torch.abs(df_train_val.audio_norm[i]))/len(df_train_val.audio_norm[i]) for i in range(len(df_train_val.audio_norm))]\n",
    "\n",
    "print(\"Maximums\")\n",
    "print(\"min:\\t\",min(maxs))\n",
    "print(\"max:\\t\",max(maxs))\n",
    "print(\"mean:\\t\",sum(maxs)/len(maxs))\n",
    "\n",
    "print(\"\\nMinimums\")\n",
    "print(\"min:\\t\",min(mins))\n",
    "print(\"max:\\t\",max(mins))\n",
    "print(\"mean:\\t\",sum(mins)/len(mins))\n",
    "\n",
    "print(\"\\nMeans\")\n",
    "print(\"min:\\t\",min(means))\n",
    "print(\"max:\\t\",max(means))\n",
    "print(\"mean:\\t\",sum(means)/len(means))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03605e0f",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.2, random_state=42, stratify=df_train_val.stratify)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27072e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Distribution of data\")\n",
    "plt.hist(df_train.sort_values('stratify').stratify)\n",
    "plt.hist(df_val.sort_values('stratify').stratify)\n",
    "plt.legend((\"Train set\", \"Validation set\"))\n",
    "plt.xlabel(\"Combined labels\")\n",
    "plt.ylabel(\"Number of samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2ec99",
   "metadata": {},
   "source": [
    "## Turn audio into spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ade15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "if (not os.path.isdir(\"preprocessed\")): os.mkdir(\"preprocessed\")\n",
    "if (not os.path.isdir(\"preprocessed/train\")): os.mkdir(\"preprocessed/train\")\n",
    "if (not os.path.isdir(\"preprocessed/train/specs\")): os.mkdir(\"preprocessed/train/specs\")\n",
    "if (not os.path.isdir(\"preprocessed/val\")): os.mkdir(\"preprocessed/val\")\n",
    "if (not os.path.isdir(\"preprocessed/val/specs\")): os.mkdir(\"preprocessed/val/specs\")\n",
    "\n",
    "labels_csv_out = \"\"\n",
    "\n",
    "for i in range(len(df_train.looped_audio)):\n",
    "    S = librosa.feature.melspectrogram(y=df_train.looped_audio[i].numpy(), sr=16000)\n",
    "    labels_csv_out += \",\".join([f\"{df_train.file_name[i][:-4]}.npy\", str(df_train.accent[i]),\"\\n\"])\n",
    "    np.save(f'preprocessed/train/specs/{df_train.file_name[i][:-4]}.npy', S)\n",
    "\n",
    "with open(\"preprocessed/train/labels.csv\", \"w+\") as f:\n",
    "    f.write(labels_csv_out)\n",
    "\n",
    "labels_csv_out = \"\"\n",
    "\n",
    "for i in range(len(df_val.looped_audio)):\n",
    "    S = librosa.feature.melspectrogram(y=df_val.looped_audio[i].numpy(), sr=16000)\n",
    "    labels_csv_out += \",\".join([f\"{df_val.file_name[i][:-4]}.npy\", str(df_val.accent[i]), \"\\n\"])\n",
    "    np.save(f'preprocessed/val/specs/{df_val.file_name[i][:-4]}.npy', S)\n",
    "\n",
    "\n",
    "with open(\"preprocessed/val/labels.csv\", \"w+\") as f:\n",
    "    f.write(labels_csv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.feature.melspectrogram(y=df_train_val.looped_audio[0].numpy(), sr=16000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity check\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "S = np.load(f\"preprocessed/train/specs/{os.listdir('preprocessed/train/specs')[1]}\")\n",
    "fig, ax = plt.subplots()\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "img = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=16000, ax=ax)\n",
    "\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "\n",
    "ax.set(title='Mel-frequency spectrogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da9c41",
   "metadata": {},
   "source": [
    "## Process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bce3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>audio</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5775</td>\n",
       "      <td>5775.wav</td>\n",
       "      <td>[tensor(0.0003), tensor(0.0002), tensor(0.0002...</td>\n",
       "      <td>3.498687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5652</td>\n",
       "      <td>5652.wav</td>\n",
       "      <td>[tensor(-9.1553e-05), tensor(-9.1553e-05), ten...</td>\n",
       "      <td>5.125625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5740</td>\n",
       "      <td>5740.wav</td>\n",
       "      <td>[tensor(0.), tensor(3.0518e-05), tensor(-3.051...</td>\n",
       "      <td>2.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6428</td>\n",
       "      <td>6428.wav</td>\n",
       "      <td>[tensor(0.), tensor(6.1035e-05), tensor(0.0002...</td>\n",
       "      <td>7.253312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8021</td>\n",
       "      <td>8021.wav</td>\n",
       "      <td>[tensor(0.0003), tensor(0.0002), tensor(0.0001...</td>\n",
       "      <td>4.010625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id file_name                                              audio    length\n",
       "0  5775  5775.wav  [tensor(0.0003), tensor(0.0002), tensor(0.0002...  3.498687\n",
       "1  5652  5652.wav  [tensor(-9.1553e-05), tensor(-9.1553e-05), ten...  5.125625\n",
       "2  5740  5740.wav  [tensor(0.), tensor(3.0518e-05), tensor(-3.051...  2.637500\n",
       "3  6428  6428.wav  [tensor(0.), tensor(6.1035e-05), tensor(0.0002...  7.253312\n",
       "4  8021  8021.wav  [tensor(0.0003), tensor(0.0002), tensor(0.0001...  4.010625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>audio</th>\n",
       "      <th>length</th>\n",
       "      <th>looped_audio</th>\n",
       "      <th>looped_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5775</td>\n",
       "      <td>5775.wav</td>\n",
       "      <td>[tensor(0.0003), tensor(0.0002), tensor(0.0002...</td>\n",
       "      <td>3.498687</td>\n",
       "      <td>[tensor(0.0003), tensor(0.0002), tensor(0.0002...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5652</td>\n",
       "      <td>5652.wav</td>\n",
       "      <td>[tensor(-9.1553e-05), tensor(-9.1553e-05), ten...</td>\n",
       "      <td>5.125625</td>\n",
       "      <td>[tensor(-9.1553e-05), tensor(-9.1553e-05), ten...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5740</td>\n",
       "      <td>5740.wav</td>\n",
       "      <td>[tensor(0.), tensor(3.0518e-05), tensor(-3.051...</td>\n",
       "      <td>2.637500</td>\n",
       "      <td>[tensor(0.), tensor(3.0518e-05), tensor(-3.051...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6428</td>\n",
       "      <td>6428.wav</td>\n",
       "      <td>[tensor(0.), tensor(6.1035e-05), tensor(0.0002...</td>\n",
       "      <td>7.253312</td>\n",
       "      <td>[tensor(0.), tensor(6.1035e-05), tensor(0.0002...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8021</td>\n",
       "      <td>8021.wav</td>\n",
       "      <td>[tensor(0.0003), tensor(0.0002), tensor(0.0001...</td>\n",
       "      <td>4.010625</td>\n",
       "      <td>[tensor(0.0003), tensor(0.0002), tensor(0.0001...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id file_name                                              audio  \\\n",
       "0  5775  5775.wav  [tensor(0.0003), tensor(0.0002), tensor(0.0002...   \n",
       "1  5652  5652.wav  [tensor(-9.1553e-05), tensor(-9.1553e-05), ten...   \n",
       "2  5740  5740.wav  [tensor(0.), tensor(3.0518e-05), tensor(-3.051...   \n",
       "3  6428  6428.wav  [tensor(0.), tensor(6.1035e-05), tensor(0.0002...   \n",
       "4  8021  8021.wav  [tensor(0.0003), tensor(0.0002), tensor(0.0001...   \n",
       "\n",
       "     length                                       looped_audio  looped_length  \n",
       "0  3.498687  [tensor(0.0003), tensor(0.0002), tensor(0.0002...           13.0  \n",
       "1  5.125625  [tensor(-9.1553e-05), tensor(-9.1553e-05), ten...           13.0  \n",
       "2  2.637500  [tensor(0.), tensor(3.0518e-05), tensor(-3.051...           13.0  \n",
       "3  7.253312  [tensor(0.), tensor(6.1035e-05), tensor(0.0002...           13.0  \n",
       "4  4.010625  [tensor(0.0003), tensor(0.0002), tensor(0.0001...           13.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>audio</th>\n",
       "      <th>length</th>\n",
       "      <th>looped_audio</th>\n",
       "      <th>looped_length</th>\n",
       "      <th>audio_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5775</td>\n",
       "      <td>5775.wav</td>\n",
       "      <td>[tensor(0.0003), tensor(0.0002), tensor(0.0002...</td>\n",
       "      <td>3.498687</td>\n",
       "      <td>[tensor(0.0003), tensor(0.0002), tensor(0.0002...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[tensor(0.0007), tensor(0.0004), tensor(0.0004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5652</td>\n",
       "      <td>5652.wav</td>\n",
       "      <td>[tensor(-9.1553e-05), tensor(-9.1553e-05), ten...</td>\n",
       "      <td>5.125625</td>\n",
       "      <td>[tensor(-9.1553e-05), tensor(-9.1553e-05), ten...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[tensor(-0.0001), tensor(-0.0001), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5740</td>\n",
       "      <td>5740.wav</td>\n",
       "      <td>[tensor(0.), tensor(3.0518e-05), tensor(-3.051...</td>\n",
       "      <td>2.637500</td>\n",
       "      <td>[tensor(0.), tensor(3.0518e-05), tensor(-3.051...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[tensor(0.), tensor(5.0774e-05), tensor(-5.077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6428</td>\n",
       "      <td>6428.wav</td>\n",
       "      <td>[tensor(0.), tensor(6.1035e-05), tensor(0.0002...</td>\n",
       "      <td>7.253312</td>\n",
       "      <td>[tensor(0.), tensor(6.1035e-05), tensor(0.0002...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[tensor(0.), tensor(0.0002), tensor(0.0005), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8021</td>\n",
       "      <td>8021.wav</td>\n",
       "      <td>[tensor(0.0003), tensor(0.0002), tensor(0.0001...</td>\n",
       "      <td>4.010625</td>\n",
       "      <td>[tensor(0.0003), tensor(0.0002), tensor(0.0001...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[tensor(0.0004), tensor(0.0003), tensor(0.0002...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id file_name                                              audio  \\\n",
       "0  5775  5775.wav  [tensor(0.0003), tensor(0.0002), tensor(0.0002...   \n",
       "1  5652  5652.wav  [tensor(-9.1553e-05), tensor(-9.1553e-05), ten...   \n",
       "2  5740  5740.wav  [tensor(0.), tensor(3.0518e-05), tensor(-3.051...   \n",
       "3  6428  6428.wav  [tensor(0.), tensor(6.1035e-05), tensor(0.0002...   \n",
       "4  8021  8021.wav  [tensor(0.0003), tensor(0.0002), tensor(0.0001...   \n",
       "\n",
       "     length                                       looped_audio  looped_length  \\\n",
       "0  3.498687  [tensor(0.0003), tensor(0.0002), tensor(0.0002...           13.0   \n",
       "1  5.125625  [tensor(-9.1553e-05), tensor(-9.1553e-05), ten...           13.0   \n",
       "2  2.637500  [tensor(0.), tensor(3.0518e-05), tensor(-3.051...           13.0   \n",
       "3  7.253312  [tensor(0.), tensor(6.1035e-05), tensor(0.0002...           13.0   \n",
       "4  4.010625  [tensor(0.0003), tensor(0.0002), tensor(0.0001...           13.0   \n",
       "\n",
       "                                          audio_norm  \n",
       "0  [tensor(0.0007), tensor(0.0004), tensor(0.0004...  \n",
       "1  [tensor(-0.0001), tensor(-0.0001), tensor(-0.0...  \n",
       "2  [tensor(0.), tensor(5.0774e-05), tensor(-5.077...  \n",
       "3  [tensor(0.), tensor(0.0002), tensor(0.0005), t...  \n",
       "4  [tensor(0.0004), tensor(0.0003), tensor(0.0002...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pre-process test set\n",
    "import convenience\n",
    "import torch\n",
    "df_test, sample_rates = convenience.load_test()\n",
    "display(df_test.head())\n",
    "\n",
    "target_duration = 13\n",
    "sr = 16000\n",
    "\n",
    "df_test, _ = convenience.loop_audio_df(df_test, target_duration=target_duration, sr=sr)\n",
    "display(df_test.head())\n",
    "\n",
    "df_test['audio_norm'] = df_test.looped_audio/[torch.max(torch.abs(df_test.looped_audio[i])) for i in range(len(df_test.looped_audio))]\n",
    "display(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfffd265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export test set\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "if (not os.path.isdir(\"preprocessed\")): os.mkdir(\"preprocessed\")\n",
    "if (not os.path.isdir(\"preprocessed/test\")): os.mkdir(\"preprocessed/test\")\n",
    "if (not os.path.isdir(\"preprocessed/test/specs\")): os.mkdir(\"preprocessed/test/specs\")\n",
    "\n",
    "\n",
    "labels_csv_out = \"Id,label\\n\"\n",
    "\n",
    "for i in range(len(df_test.looped_audio)):\n",
    "    S = librosa.feature.melspectrogram(y=df_test.looped_audio[i].numpy(), sr=16000)\n",
    "    labels_csv_out += \",\".join([f\"{df_test.id[i]}\",\"\\n\"])\n",
    "    np.save(f'preprocessed/test/specs/{df_test.file_name[i][:-4]}.npy', S)\n",
    "\n",
    "with open(\"preprocessed/test/labels.csv\", \"w+\") as f:\n",
    "    f.write(labels_csv_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_accent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
